{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ4jyS3U1b-A"
      },
      "source": [
        "# Image Preprocessing and Binary Classification with Keras\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this week's exercise, you will:\n",
        "1. Learn how to do image preprocessing in Keras\n",
        "2. Build a multilayer neural network for binary classification\n",
        "3. Train the model on a real-world dataset of cats and dogs\n",
        "4. Monitor performance using a validation dataset\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries\n",
        "\n",
        "Let's start by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UtCyL5F31b-G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, Rescaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JyyA-nt1b-J"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Load and Preprocess the Data\n",
        "\n",
        "Use `tfds.load()` to load the \"cats_vs_dogs\" dataset.\n",
        "\n",
        "Find a way to split the dataset into a training and a validation set.\n",
        "\n",
        "Also research how to apply necessary preprocessing to the data and do so (some of the preprocessing can also later be done using layers of the model).\n",
        "\n",
        "*Note*: You can also get the dataset from other sources. However, there are some known issues with corrupted images, which then need to be addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ea7BbYYt1b-K"
      },
      "outputs": [],
      "source": [
        "# TODO: load the dataset\n",
        "def load_data():\n",
        "    dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "    train_data, test_data = dataset['train'], dataset['test']\n",
        "    return train_data, test_data, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpIra7lY1b-L"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 3: Build a Multilayer Neural Network\n",
        "\n",
        "Build a multilayer neural network for binary classification. Apply your knowledge from the Coursera lectures to choose an adequate model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Km65DfYF1b-L"
      },
      "outputs": [],
      "source": [
        "# TODO build a model\n",
        "model = Sequential([\n",
        "    Input(shape=(128, 128, 3)),\n",
        "    Rescaling(1./255),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "# TODO compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUTCwEM1b-M"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 4: Train the Model\n",
        "\n",
        "Train the model using the training dataset you created. Monitor performance during training using the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UBLUtOCI1b-M"
      },
      "outputs": [],
      "source": [
        "# TODO: train the model\n",
        "def train_model(train_data, test_data):\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 10\n",
        "\n",
        "    train_data = train_data.map(lambda x, y: (tf.image.resize(x, (128, 128)), y))\n",
        "    test_data = test_data.map(lambda x, y: (tf.image.resize(x, (128, 128)), y))\n",
        "\n",
        "    train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    test_data = test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    history = model.fit(train_data, epochs=EPOCHS, validation_data=test_data)\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zic081tj1b-N"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 5: Evaluate the Model\n",
        "\n",
        "After training, you may upload some test images to evaluate your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mTimZhGK1b-O"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91063263aadf445ebdcf7bd2f92ac9b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value=(), accept='image/*', description='Upload', multiple=True)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def load_and_predict(model):\n",
        "    uploader = widgets.FileUpload(accept='image/*', multiple=True)\n",
        "    display(uploader)\n",
        "\n",
        "    def on_upload_change(change):\n",
        "        for filename, fileinfo in uploader.value.items():\n",
        "            img = Image.open(io.BytesIO(fileinfo['content']))\n",
        "            img = img.resize((128, 128))\n",
        "            x = image.img_to_array(img)\n",
        "            x = np.expand_dims(x, axis=0) / 255.0\n",
        "\n",
        "            classes = model.predict(x)\n",
        "            result = \"a dog\" if classes[0] > 0.5 else \"a cat\"\n",
        "            print(f'The model predicts that the image is of {result}')\n",
        "\n",
        "    uploader.observe(on_upload_change, names='value')\n",
        "\n",
        "# Call the function to upload images and get predictions\n",
        "load_and_predict(model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
